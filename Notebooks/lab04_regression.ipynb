{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab04_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrqTzbnq1Aw_"
      },
      "source": [
        "# 데이터 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hhVd4YJR2WA"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/TeamAIoT/deep-learning/main/Dataset/boston_description.txt\n",
        "!wget https://raw.githubusercontent.com/TeamAIoT/deep-learning/main/Dataset/boston_train.csv\n",
        "!wget https://raw.githubusercontent.com/TeamAIoT/deep-learning/main/Dataset/boston_test.csv\n",
        "!wget https://raw.githubusercontent.com/TeamAIoT/deep-learning/main/Dataset/diabetes_description.txt\n",
        "!wget https://raw.githubusercontent.com/TeamAIoT/deep-learning/main/Dataset/diabetes_train.csv\n",
        "!wget https://raw.githubusercontent.com/TeamAIoT/deep-learning/main/Dataset/diabetes_test.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HDiYpch1D79"
      },
      "source": [
        "# 모듈 임포트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HvhfVzjSm3d"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.cuda import is_available"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2093Rp-w1GYq"
      },
      "source": [
        "# GPU 사용을 위한 Device 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DAy8NYRbSox"
      },
      "source": [
        "device='cuda' if is_available() else 'cpu'\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLfE9tr11xtd"
      },
      "source": [
        "# Boston Housing Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Hk5IGf1TVe"
      },
      "source": [
        "## Boston Housing Dataset 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "688OYwJwS48x"
      },
      "source": [
        "class BostonDataset(Dataset):\n",
        "    def __init__(self,mode='train'):\n",
        "        with open('boston_description.txt') as f:\n",
        "            print(f.read())\n",
        "        self.mode=mode\n",
        "        if self.mode=='train':\n",
        "            if os.path.exists('boston_train.csv'):\n",
        "                self.data=pd.read_csv('boston_train.csv')\n",
        "            else:\n",
        "                raise FileNotFoundError\n",
        "        elif self.mode=='test':\n",
        "            if os.path.exists('boston_test.csv'):\n",
        "                self.data=pd.read_csv('boston_test.csv')\n",
        "            else:\n",
        "                raise FileNotFoundError\n",
        "        else:\n",
        "            raise ValueError('Invaild argument at \\'mode\\'. expected \\'train\\' or \\'test\\'')\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return torch.FloatTensor(self.data.iloc[idx,:13].values),torch.FloatTensor(self.data.iloc[idx,[-1]].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEVoew1e1XTy"
      },
      "source": [
        "## 학습을 위한 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-CV3PqzYrHL"
      },
      "source": [
        "batch_size=32\n",
        "train_ratio=0.8\n",
        "\n",
        "all_data=BostonDataset(mode='train')\n",
        "\n",
        "train_data_len=int(len(all_data)*0.8)\n",
        "valid_data_len=len(all_data)-train_data_len\n",
        "\n",
        "train_data,valid_data=random_split(all_data,[train_data_len,valid_data_len])\n",
        "\n",
        "train_loader=DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
        "valid_loader=DataLoader(valid_data,batch_size=batch_size,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D54C_BeQ1c8t"
      },
      "source": [
        "## BostonModel 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmiBorXiZ3hf"
      },
      "source": [
        "class BostonModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BostonModel,self).__init__()\n",
        "        self.layer1=nn.Linear(13,16)\n",
        "        self.layer2=nn.Linear(16,1)\n",
        "        self.activation=nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.layer1(x)\n",
        "        x=self.activation(x)\n",
        "        x=self.layer2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdqxADmt1g6G"
      },
      "source": [
        "## 모델, 손실 함수, 최적화 알고리즘 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C74ijPkha1JJ"
      },
      "source": [
        "lr=0.001\n",
        "\n",
        "model=BostonModel()\n",
        "criterion=nn.MSELoss()\n",
        "optimizer=optim.SGD(model.parameters(),lr=lr)\n",
        "\n",
        "model=model.to(device)\n",
        "criterion=criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-WYXl5d1lZo"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm_kYtDgawXl"
      },
      "source": [
        "def train(model,criterion,optimizer,train_loader,valid_loader,num_epochs=10,print_every=1,early_stop=None,model_path='boston.pth'):\n",
        "    train_logs=[]\n",
        "    valid_logs=[]\n",
        "    patience=0\n",
        "    best_loss=np.inf\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss=0\n",
        "        valid_loss=0\n",
        "        # training step\n",
        "        model.train()\n",
        "        for data,target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            data,target=data.to(device),target.to(device)\n",
        "            pred=model(data)\n",
        "            loss=criterion(pred,target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss+=loss.item()*data.size(0)\n",
        "        train_loss/=len(train_data)\n",
        "        train_logs.append(train_loss)\n",
        "        if (epoch+1)%print_every==0:\n",
        "            print('Training   Epoch {} - Loss : {:.8f}'.format(epoch,train_loss))\n",
        "        # validation step\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for data,target in valid_loader:\n",
        "                data,target=data.to(device),target.to(device)\n",
        "                pred=model(data)\n",
        "                loss=criterion(pred,target)\n",
        "                valid_loss+=loss.item()*data.size(0)\n",
        "            valid_loss/=len(valid_data)\n",
        "            valid_logs.append(valid_loss)\n",
        "            if (epoch+1)%print_every==0:\n",
        "                print('Validation Epoch {} - Loss : {:.8f}'.format(epoch,valid_loss))\n",
        "            if valid_loss<best_loss:\n",
        "                best_loss=valid_loss\n",
        "                torch.save(model.state_dict(),model_path)\n",
        "                if early_stop is not None:\n",
        "                    patience=0\n",
        "            elif early_stop is not None:\n",
        "                patience+=1\n",
        "                if patience>=early_stop:\n",
        "                    print('Training finished by early stopping')\n",
        "                    return train_logs,valid_logs\n",
        "    return train_logs,valid_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTPS6XHbelDt"
      },
      "source": [
        "train_logs,valid_logs = train(model=model,\n",
        "                              criterion=criterion,\n",
        "                              optimizer=optimizer,\n",
        "                              train_loader=train_loader,\n",
        "                              valid_loader=valid_loader,\n",
        "                              num_epochs=100,\n",
        "                              print_every=10,\n",
        "                              early_stop=None,\n",
        "                              model_path='boston.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgxF8akIhb9U"
      },
      "source": [
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot([i for i in range(len(train_logs))],train_logs,label='train_loss')\n",
        "plt.plot([i for i in range(len(valid_logs))],valid_logs,label='valid_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_2IxT6w1nQt"
      },
      "source": [
        "## 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhuwd04LuFvL"
      },
      "source": [
        "test_data=BostonDataset(mode='test')\n",
        "test_loader=DataLoader(test_data,batch_size=1,shuffle=False)\n",
        "\n",
        "model.load_state_dict(torch.load('boston.pth'))\n",
        "model=model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1vPnF9juQKX"
      },
      "source": [
        "def test(model,criterion,test_loader):\n",
        "    test_loss=0\n",
        "    result_table=pd.DataFrame(columns=['Prediction','Target'])\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data,target in test_loader:\n",
        "            data,target=data.to(device),target.to(device)\n",
        "            pred=model(data)\n",
        "            loss=criterion(pred,target)\n",
        "            test_loss+=loss.item()*data.size(0)\n",
        "            for p,t in zip(pred.view(-1),target.view(-1)):\n",
        "                result_table=result_table.append({'Prediction':p.item(),'Target':t.item()},ignore_index=True)\n",
        "        test_loss/=len(test_data)\n",
        "    return test_loss,result_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs-O0jVhu0pi"
      },
      "source": [
        "test_loss,result_table=test(model=model,\n",
        "                            criterion=criterion,\n",
        "                            test_loader=test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJHKArfBwIkl"
      },
      "source": [
        "print('Test Loss : {}'.format(test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMRUa6TAx2Bc"
      },
      "source": [
        "result_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SlZ-8KF11Ow"
      },
      "source": [
        "# Diabetes Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHFWSxZT2dpD"
      },
      "source": [
        "## Diabetes Dataset 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvllRSMp23Ax"
      },
      "source": [
        "class DiabetesDataset(Dataset):\n",
        "    def __init__(self,mode='train'):\n",
        "        with open('diabetes_description.txt') as f:\n",
        "            print(f.read())\n",
        "        self.mode=mode\n",
        "        if self.mode=='train':\n",
        "            if os.path.exists('diabetes_train.csv'):\n",
        "                self.data=pd.read_csv('diabetes_train.csv')\n",
        "            else:\n",
        "                raise FileNotFoundError\n",
        "        elif self.mode=='test':\n",
        "            if os.path.exists('diabetes_test.csv'):\n",
        "                self.data=pd.read_csv('diabetes_test.csv')\n",
        "            else:\n",
        "                raise FileNotFoundError\n",
        "        else:\n",
        "            raise ValueError('Invaild argument at \\'mode\\'. expected \\'train\\' or \\'test\\'')\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return torch.FloatTensor(self.data.iloc[idx,:10].values),torch.FloatTensor(self.data.iloc[idx,[-1]].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtrHOJtb2ht_"
      },
      "source": [
        "## 학습을 위한 데이터 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yNyIv1O3KQr"
      },
      "source": [
        "batch_size=32\n",
        "train_ratio=0.8\n",
        "\n",
        "all_data=DiabetesDataset(mode='train')\n",
        "\n",
        "train_data_len=int(len(all_data)*0.8)\n",
        "valid_data_len=len(all_data)-train_data_len\n",
        "\n",
        "train_data,valid_data=random_split(all_data,[train_data_len,valid_data_len])\n",
        "\n",
        "train_loader=DataLoader(train_data,batch_size=batch_size,shuffle=True)\n",
        "valid_loader=DataLoader(valid_data,batch_size=batch_size,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeVRCvKr2lLL"
      },
      "source": [
        "## DiabetesModel 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3lJ3NtG3Qmv"
      },
      "source": [
        "class DiabetesModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DiabetesModel,self).__init__()\n",
        "        self.layer1=nn.Linear(10,16)\n",
        "        self.layer2=nn.Linear(16,1)\n",
        "        self.activation=nn.Sigmoid()\n",
        "\n",
        "    def forward(self,x):\n",
        "        x=self.layer1(x)\n",
        "        x=self.activation(x)\n",
        "        x=self.layer2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbJti3fJ2pfj"
      },
      "source": [
        "## 모델, 손실 함수, 최적화 알고리즘 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcDMSGVV3VLi"
      },
      "source": [
        "lr=0.001\n",
        "\n",
        "model=DiabetesModel()\n",
        "criterion=nn.MSELoss()\n",
        "optimizer=optim.SGD(model.parameters(),lr=lr)\n",
        "\n",
        "model=model.to(device)\n",
        "criterion=criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faE8Z31I2t3l"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJZk3Cy03eyJ"
      },
      "source": [
        "def train(model,criterion,optimizer,train_loader,valid_loader,num_epochs=10,print_every=1,early_stop=None,model_path='diabetes.pth'):\n",
        "    train_logs=[]\n",
        "    valid_logs=[]\n",
        "    patience=0\n",
        "    best_loss=np.inf\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss=0\n",
        "        valid_loss=0\n",
        "        # training step\n",
        "        model.train()\n",
        "        for data,target in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            data,target=data.to(device),target.to(device)\n",
        "            pred=model(data)\n",
        "            loss=criterion(pred,target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss+=loss.item()*data.size(0)\n",
        "        train_loss/=len(train_data)\n",
        "        train_logs.append(train_loss)\n",
        "        if (epoch+1)%print_every==0:\n",
        "            print('Training   Epoch {} - Loss : {:.8f}'.format(epoch,train_loss))\n",
        "        # validation step\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for data,target in valid_loader:\n",
        "                data,target=data.to(device),target.to(device)\n",
        "                pred=model(data)\n",
        "                loss=criterion(pred,target)\n",
        "                valid_loss+=loss.item()*data.size(0)\n",
        "            valid_loss/=len(valid_data)\n",
        "            valid_logs.append(valid_loss)\n",
        "            if (epoch+1)%print_every==0:\n",
        "                print('Validation Epoch {} - Loss : {:.8f}'.format(epoch,valid_loss))\n",
        "            if valid_loss<best_loss:\n",
        "                best_loss=valid_loss\n",
        "                torch.save(model.state_dict(),model_path)\n",
        "                if early_stop is not None:\n",
        "                    patience=0\n",
        "            elif early_stop is not None:\n",
        "                patience+=1\n",
        "                if patience>=early_stop:\n",
        "                    print('Training finished by early stopping')\n",
        "                    return train_logs,valid_logs\n",
        "    return train_logs,valid_logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h4k-ANF3i0x"
      },
      "source": [
        "train_logs,valid_logs = train(model=model,\n",
        "                              criterion=criterion,\n",
        "                              optimizer=optimizer,\n",
        "                              train_loader=train_loader,\n",
        "                              valid_loader=valid_loader,\n",
        "                              num_epochs=100,\n",
        "                              print_every=10,\n",
        "                              early_stop=None,\n",
        "                              model_path='diabetes.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp2Fq2Sd3lW9"
      },
      "source": [
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot([i for i in range(len(train_logs))],train_logs,label='train_loss')\n",
        "plt.plot([i for i in range(len(valid_logs))],valid_logs,label='valid_loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIK-wRue2vIX"
      },
      "source": [
        "## 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKV_1L5-3oIA"
      },
      "source": [
        "test_data=DiabetesDataset(mode='test')\n",
        "test_loader=DataLoader(test_data,batch_size=1,shuffle=False)\n",
        "\n",
        "model.load_state_dict(torch.load('diabetes.pth'))\n",
        "model=model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs93Ydfv3znB"
      },
      "source": [
        "def test(model,criterion,test_loader):\n",
        "    test_loss=0\n",
        "    result_table=pd.DataFrame(columns=['Prediction','Target'])\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data,target in test_loader:\n",
        "            data,target=data.to(device),target.to(device)\n",
        "            pred=model(data)\n",
        "            loss=criterion(pred,target)\n",
        "            test_loss+=loss.item()*data.size(0)\n",
        "            for p,t in zip(pred.view(-1),target.view(-1)):\n",
        "                result_table=result_table.append({'Prediction':p.item(),'Target':t.item()},ignore_index=True)\n",
        "        test_loss/=len(test_data)\n",
        "    return test_loss,result_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2ohhJe730ZZ"
      },
      "source": [
        "test_loss,result_table=test(model=model,\n",
        "                            criterion=criterion,\n",
        "                            test_loader=test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88eSB7MR30_d"
      },
      "source": [
        "print('Test Loss : {}'.format(test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9jkRj8z34_f"
      },
      "source": [
        "result_table"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}